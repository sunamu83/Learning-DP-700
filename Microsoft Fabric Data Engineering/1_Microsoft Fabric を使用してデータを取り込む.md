[Microsoft Fabric を使用してデータを取り込む](https://learn.microsoft.com/ja-jp/training/paths/ingest-data-with-microsoft-fabric/)

1. Microsoft Fabric でデータフロー Gen2 を使用してデータを取り込む  
[Microsoft Fabric でデータフロー Gen2 を使用してデータを取り込む](https://learn.microsoft.com/ja-jp/training/modules/use-dataflow-gen-2-fabric/)  
**学習の目標**
- Microsoft Fabricのデータフロー機能について説明する
- データを取り込んで変換するためのデータフローソリューションを作成する
- パイプラインにデータフローを含める

1.1. はじめに  
データフローGen2は複数のソースからデータを取り込んで変換し、クレンジングされたデータを別の宛先に格納するために使用される。  
データパイプラインに組み込むこともBIのデータソースにすることもできる。  


1.2. Microsoft Fabric のデータフロー Gen2 について  
データフローGen2はPower Query Onlineを使用するETLツール  
データフローGen2も目的はETLタスクを実行するための簡単で再利用可能な方法を提供すること  
データの宛先を指定せず変換方法のみ定義した状態でパイプラインに追加し、後続のアクティビティに変換後の状態を渡すことも可能。  
パイプラインでレイクハウスにデータを読み込み、データフローで変換し、そのデータフローをセマンティックとしてレポートのデータソースにすることも可能。  

1.3. Microsoft Fabric のデータフロー Gen2 について詳しく確認する
行レベルセキュリティはサポートしていない。  
クエリの設定ペインに表示されるデータ宛先オプションは、レイクハウス・Warehouse・SQL database・Azure SQL database・Azure Data Explorer・Azure Synapse Analyticsを設定することができる。

1.4. Microsoft Fabric でデータフロー Gen2 とパイプラインを統合する
データフローGen2はパイプラインと組み合わせると変換されたデータに対して塚の操作を実行する必要がある場合に便利  
パイプラインに組み込みデータフローの完了後にスクリプト・ストアドプロシージャの実行・メタデータの取得など追加のアクティビティを実行することも可能。  
データパイプラインはデータフローを実行するためにスケジューリングすることもトリガーによって実行することも可能。パイプラインを使用してデータフローを実行することで手動で実行する必要がなくなる。

2. Microsoft Fabricを使用してプロセスとデータ移動のオーケストレーションを行う
[Microsoft Fabricを使用してプロセスとデータ移動のオーケストレーションを行う](https://learn.microsoft.com/ja-jp/training/modules/use-data-factory-pipelines-fabric/)
**学習の目的**
- パイプライン機能について説明する
- パイプラインでコピーアクティビティを使用する
- 定義済みのテンプレートに基づいてパイプラインを作成する
- パイプラインを実行して監視する

2.1. はじめに  
データパイプラインを用いるとデータの抽出を行い宛先への読み込みに加えて、途中での変換を行う一連のアクティビティを定義できる  ETLプロセスを自動かするために使用される
Azure Data Factoryに似ている  

2.2. パイプラインについて  
データの移動と処理のタスクを時刻するアクティビティがカプセル化している。  
アクティビティには2つのカテゴリがある。  
・データの変換：データコピー、データフローGen2、Notebook、ストアドプロシージャ、データの削除  
・制御アクティビティ：分岐・ループ、変数・パラメータの管理  
アクティビティを順番に接続することでフローを定義する  
  
2.3. データのコピーアクティビティを使用する  
外部ソースからレイクハウスのファイル・テーブルにデータを取り込むのに使用される一般的なアクティビティ  
データソースの状態から変換を挟まずにターゲットにコピーしたい場合、または後続のアクティビティで変換を行う場合に用いる。データに変換を要する場合、または複数のソースからデータをマージする必要がある場合にはデータフローGen2を実行する。  

2.4. パイプラインテンプレートを使用する  
一般的なパイプラインシナリオのテンプレートが用意されており、それをカスタマイズしながら用いることが可能  

2.5. パイプラインを実行して監視する  
[検証]オプションで構成が有効かどうかを確認できる  
実行履歴から個別のアクティビティの実行時間を確認することもできる。

3. Microsoft Fabricのリアルタイムインテリジェンスの使用を開始する
[Microsoft Fabricのリアルタイムインテリジェンスの使用を開始する](https://learn.microsoft.com/ja-jp/training/modules/get-started-kusto-fabric/)
**学習の目的**
- イベントデータのリアルタイムストリームのキャプチャ、分析、可視化、操作が可能なリアルタイムインテリジェンス機能を学ぶ

3.1. はじめに  
データ分析は"バッチデータ分析"と"リアルタイムデータ分析"の2つに大別される。本項目では最小限のコーディングによってリアルタイムデータ分析ソリューションを構築する方法を学ぶ。  
  
3.2. リアルタイムデータ分析とは  
リアルタイムデータ分析は、永続的な一連のデータで構成されるデータ"ストリーム"のインジェスト　と　処理　に基づく。  
リアルタイム分析には次の共通の目的がある。  
- 問題・傾向を報告するためにデータを継続的に分析する
- 今後の昨日強化の計画に生かすため、様々な状況でのシステムの挙動について理解する
- 特定のイベントが発生したときや閾値を超えたときに、アクションやアラートをトリガーする。

○リアルタイムデータ分析のためのストリーム処理の特性
- ストリームは無制限、終わりがなく永続的にデータがストリームに追加される
- ストリーム内のレコードには通常、レコードが関連するイベントがいつ発生したかを示す時間ベースのデータが含まれる
- ストリームデータの集計は、"ウィンドウ"で実行されることが多い。1分あたりの○○など
- 処理結果を用いてリアルタイムの自動化・可視化をサポートしたり、データストアに保持して、他のデータと組み合わせて分析することも可能。

3.3. Microsoft FabricのReal-Time Intelligence  
Fabricのリアルタイムインテリジェンスを用いると以下のことができる。  
- データのキャプチャ、取り込みを行うイベントストリームが作成できる。  
- キャプチャしたデータをイベントハウスに格納する。これには1つ以上のKQLデータベースが含まれる。クエリセットを用いて分析が行える。  
- リアルタイムダッシュボードまたはPower BIで可視化する。  
- アクティベーターを使用して自動アクションをトリガーするアラートを構成する。  
これらのリソースは、リアルタイムハブから管理できる。  

3.4. リアルタイムデータの取り込みと変換  
イベントストリームはキャプチャ・変換・読み込みに使用する。  
データソース：外部サービスやFabricイベントなど  
データ変換：    
　フィルター：フィールドの値に基づきイベントをフィルター  
　フィールドの管理：型の変更や列の追加・削除、名前変更  
　集計：一定期間内にイベントが発生するたびに集計を計算する、データ内の他のディメンションに基づいて集計をフィルター/スライスすることも可能。  
　Group by変換：特定の時間枠内の全てのイベントの集計を計算する  
　和集合：2つ以上のノードを接続、名前と型が同じフィールドを持つイベントを1つのテーブルに統合、一致しないフィールドは削除  
　展開：配列内の値を新しい行に展開  
　結合：2つのストリームデータを一致条件に基づいて結合  
データの同期先：Eventhouse、レイクハウス、派生ストリーム（別のeventstreamにリダイレクト）、Fabric Activator（アクションを自動かするエージェント）、カスタムエンドポイント（外部システムに送信可能）  

3.5. リアルタイムデータの格納とクエリ  
Eventhouseはfabric上での一般的なリアルタイムデータの格納先  
KQLデータベース（データストア）とKQLクエリセットを作成する。  
KQLデータベース内のテーブルには、Kusto照会言語（KQL）を使用可能、読み取り専用。  
時間ベースの要素を使用した大量データに対するクエリ実行に最適化されている。  
ただし、一般的なSQLもサポートしている。  

3.6. リアルタイムデータを可視化する  
リアルタイムダッシュボードの各タイルには、イベントハウス内のテーブルからKQLクエリに基づいて情報を表示可能。ドリルダウンも可能  
Power BIでもKQLデータベースのデータを可視化可能。  

3.7. アクションを自動化する  
Activatorでイベントの自動処理が可能。メール通知やノートブックの実行など。  
Activatorは4つの概念で動作  
①イベント：ストリーム内のレコードはイベントを表す  
②オブジェクト：レコード内のデータは、なにかしらのオブジェクトを表す  
③プロパティ：データ内のフィールドが何を表すか  
④ルール：プロパティ値に基づいてアクションがトリガーされる条件  
